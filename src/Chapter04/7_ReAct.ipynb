{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReAct Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "model_name = \"gpt-4.1\"\n",
    "\n",
    "# Define the question\n",
    "question = \"\"\"Question: How deep is the Mariana Trench? \n",
    "Thought: I need to search for the Mariana Trench, then identify the deepest point recorded in this trench. \n",
    "Action: Search [Mariana Trench depth] \n",
    "Observation: The Mariana Trench is the deepest part of the world's oceans. \n",
    "Thought: The information is too general. I need specific data about the deepest point, known as the Challenger Deep. \n",
    "Action: Lookup [Challenger Deep depth] \n",
    "Observation: (Result 1 / 1) The Challenger Deep in the Mariana Trench reaches a depth of approximately 36,070 feet (10,994 meters).\n",
    " Thought: I found the specific depth of the Challenger Deep. This is the information I was looking for. \n",
    "Action: Finish [36,070 feet (10,994 meters)] \n",
    "\n",
    "Question: What is the temperature range for the area that the Great Barrier Reef extends into? \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt template\n",
    "prompt_template1 = \"\"\"\n",
    "Q: {question}\n",
    "\"\"\"\n",
    "# Create the prompt object\n",
    "prompt = PromptTemplate(template=prompt_template1, input_variables=[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to set your OPENAI_API_KEY environment variable\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    print(\"Warning: OPENAI_API_KEY environment variable not set\")\n",
    "    print(\n",
    "        \"Please set it with: os.environ['OPENAI_API_KEY'] = 'your-api-key-here'\")\n",
    "\n",
    "# Initialize the OpenAI LLM\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    openai_api_key=api_key,\n",
    "    model=model_name,\n",
    ")\n",
    "\n",
    "print(\"LLM initialized successfully!\")\n",
    "\n",
    "# Create the LLMChain with the prompt and LLM\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_response = llm_chain.run(question=question)\n",
    "print(f\"Response received from LLM! {llm_response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
